{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the training/validation resources and ontology data from AWS\n",
    "from boto.s3.connection import S3Connection, Location\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import diagnosis\n",
    "from diagnosis.KeywordExtractor import *\n",
    "from diagnosis.Diagnoser import Diagnoser\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from diagnosis.utils import group_by, flatten\n",
    "import warnings\n",
    "import pymongo\n",
    "from DataSet import fetch_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ontologies.p') as f:\n",
    "    keywords = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = set([\n",
    "    'hm/disease',\n",
    "    'biocaster/pathogens',\n",
    "    'biocaster/diseases',\n",
    "    'biocaster/symptoms',\n",
    "    'symp/symptoms',\n",
    "    'eha/symptom',\n",
    "    'eha/mode of transmission',\n",
    "    'eha/environmental factors',\n",
    "    'eha/vector',\n",
    "    'eha/occupation',\n",
    "    'eha/control measures',\n",
    "    'eha/description of infected',\n",
    "    'eha/disease category',\n",
    "    'eha/host',\n",
    "    'eha/host use',\n",
    "    'eha/symptom',\n",
    "    'eha/disease',\n",
    "    'eha/location', \n",
    "    'eha/transmission',\n",
    "    'eha/zoonotic type',\n",
    "    'eha/risk',\n",
    "    'wordnet/season',\n",
    "    'wordnet/climate',\n",
    "    'wordnet/pathogens',\n",
    "    'wordnet/hosts',\n",
    "    'wordnet/mod/severe',\n",
    "    'wordnet/mod/painful',\n",
    "    'wordnet/mod/large',\n",
    "    'wordnet/mod/rare',\n",
    "    'doid/has_symptom',\n",
    "    'doid/symptoms',\n",
    "    'doid/transmitted_by',\n",
    "    'doid/located_in',\n",
    "    'doid/diseases',\n",
    "    'doid/results_in',\n",
    "    'doid/has_material_basis_in',\n",
    "    'usgs/terrain'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keyword_array = [\n",
    "    keyword_obj for keyword_obj in keywords\n",
    "    if keyword_obj['category'] in categories\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_extractor = Pipeline([\n",
    "    ('kwext', KeywordExtractor(keyword_array)),\n",
    "    ('link', LinkedKeywordAdder(keyword_array)),\n",
    "    ('limit', LimitCounts(1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refresh dataset pickles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time_offset_test_set, mixed_test_set, training_set = fetch_datasets()\n",
    "# with open(os.path.join(pickle_dir, 'time_offset_test_set.p'), 'wb') as f:\n",
    "#     pickle.dump(time_offset_test_set, f)\n",
    "# with open(os.path.join(pickle_dir, 'mixed_test_set.p'), 'wb') as f:\n",
    "#     pickle.dump(mixed_test_set, f)\n",
    "# with open(os.path.join(pickle_dir, 'training_set.p'), 'wb') as f:\n",
    "#     pickle.dump(training_set, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset pickles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_dir = 'pickles'\n",
    "with open(os.path.join(pickle_dir, 'time_offset_test_set.p')) as f:\n",
    "    time_offset_test_set = pickle.load(f)\n",
    "with open(os.path.join(pickle_dir, 'mixed_test_set.p')) as f:\n",
    "    mixed_test_set = pickle.load(f)\n",
    "with open(os.path.join(pickle_dir, 'training_set.p')) as f:\n",
    "    training_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_offset_test_set.feature_extractor =\\\n",
    "mixed_test_set.feature_extractor =\\\n",
    "training_set.feature_extractor = feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dict_vectorizer = DictVectorizer(sparse=False).fit(training_set.get_feature_dicts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles removed because of zero feature vectors:\n",
      "0 / 4453\n",
      "Articles removed because of zero feature vectors:\n",
      "0 / 3911\n",
      "Articles removed because of zero feature vectors:\n",
      "0 / 11717\n"
     ]
    }
   ],
   "source": [
    "time_offset_test_set.dict_vectorizer = \\\n",
    "mixed_test_set.dict_vectorizer = \\\n",
    "training_set.dict_vectorizer = my_dict_vectorizer\n",
    "\n",
    "time_offset_test_set.remove_zero_feature_vectors()\n",
    "mixed_test_set.remove_zero_feature_vectors()\n",
    "training_set.remove_zero_feature_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my_classifier = OneVsRestClassifier(LogisticRegression(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_classifier = OneVsRestClassifier(DecisionTreeRegressor(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_array = np.array(training_set.get_feature_vectors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_array = np.array(training_set.get_labels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensions\n",
    "\n",
    "Feature array: 3812 x 11717\n",
    "\n",
    "Label array: 1 x 11717\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_classifier.fit(feature_array, label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_diagnoser = Diagnoser(\n",
    "    my_classifier,\n",
    "    my_dict_vectorizer,\n",
    "    keyword_array=keyword_array,\n",
    "    cutoff_ratio=.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set (micro avg):\n",
      "precision: 0.939472644119 recall: 0.940428418018 f-score: 0.939950288103\n",
      "Validation set (micro avg):\n",
      "precision: 0.801928783383 recall: 0.846382712183 f-score: 0.823556300472\n",
      "Validation set (micro avg):\n",
      "precision: 0.864066193853 recall: 0.856975381008 f-score: 0.860506180106\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    train_label_set = set(flatten(training_set.get_labels(), 1))\n",
    "    for data_set, ds_label, print_label_breakdown in [\n",
    "        (training_set, \"Training set\", False),\n",
    "        (time_offset_test_set, \"Time offset set\", True),\n",
    "        (mixed_test_set, \"Mixed test set\", False),\n",
    "    ]:\n",
    "        if len(data_set) == 0: continue\n",
    "        validation_label_set = set(flatten(data_set.get_labels(), 1))\n",
    "        not_in_train = [\n",
    "            label for label in validation_label_set\n",
    "            if (label not in train_label_set)\n",
    "        ]\n",
    "\n",
    "        predictions = [\n",
    "            tuple([\n",
    "                my_diagnoser.classifier.classes_[i]\n",
    "                for i, p in my_diagnoser.best_guess(X)\n",
    "            ])\n",
    "            for X in data_set.get_feature_vectors()\n",
    "        ]\n",
    "\n",
    "        print (\"Validation set (micro avg):\\n\"\n",
    "            \"precision: %s recall: %s f-score: %s\") %\\\n",
    "            sklearn.metrics.precision_recall_fscore_support(\n",
    "                data_set.get_labels(add_parents=True),\n",
    "                predictions,\n",
    "                average='micro')[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic regression:\n",
    "\n",
    "Training set (micro avg):\n",
    "precision: 0.939472644119 recall: 0.940428418018 f-score: 0.939950288103\n",
    "\n",
    "Time offset test set (micro avg):\n",
    "precision: 0.801928783383 recall: 0.846382712183 f-score: 0.823556300472\n",
    "\n",
    "Mixed test set (micro avg):\n",
    "precision: 0.864066193853 recall: 0.856975381008 f-score: 0.860506180106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
